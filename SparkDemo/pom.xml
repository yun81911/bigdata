<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
	<modelVersion>4.0.0</modelVersion>

	<groupId>com.baifendian.spark</groupId>
	<artifactId>spark-examples_2.10</artifactId>
	<version>1.0-SNAPSHOT</version>

	<properties>
		<project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
		<project.reporting.outputEncoding>UTF-8</project.reporting.outputEncoding>
		<spark.version>1.6.0</spark.version>
		<akka.group>com.typesafe.akka</akka.group>
		<akka.version>2.3.11</akka.version>
		<java.version>1.7</java.version>
		<maven.version>3.3.3</maven.version>
		<sbt.project.name>spark</sbt.project.name>
		<mesos.version>0.21.1</mesos.version>
		<mesos.classifier>shaded-protobuf</mesos.classifier>
		<slf4j.version>1.7.10</slf4j.version>
		<log4j.version>1.2.17</log4j.version>
		<hadoop.version>2.6.0</hadoop.version>
		<protobuf.version>2.5.0</protobuf.version>
		<yarn.version>${hadoop.version}</yarn.version>
		<hbase.version>0.98.7-hadoop2</hbase.version>
		<hbase.artifact>hbase</hbase.artifact>
		<flume.version>1.6.0</flume.version>
		<zookeeper.version>3.4.5</zookeeper.version>
		<curator.version>2.4.0</curator.version>
		<hive.group>org.spark-project.hive</hive.group>
		<!-- Version used in Maven Hive dependency -->
		<hive.version>1.2.1.spark</hive.version>
		<!-- Version used for internal directory structure -->
		<hive.version.short>1.2.1</hive.version.short>
		<derby.version>10.10.1.1</derby.version>
		<parquet.version>1.7.0</parquet.version>
		<hive.parquet.version>1.6.0</hive.parquet.version>
		<jblas.version>1.2.4</jblas.version>
		<jetty.version>8.1.14.v20131031</jetty.version>
		<orbit.version>3.0.0.v201112011016</orbit.version>
		<chill.version>0.5.0</chill.version>
		<ivy.version>2.4.0</ivy.version>
		<oro.version>2.0.8</oro.version>
		<codahale.metrics.version>3.1.2</codahale.metrics.version>
		<avro.version>1.7.7</avro.version>
		<avro.mapred.classifier>hadoop2</avro.mapred.classifier>
		<jets3t.version>0.7.1</jets3t.version>
		<aws.kinesis.client.version>1.6.1</aws.kinesis.client.version>
		<!-- the producer is used in tests -->
		<aws.kinesis.producer.version>0.10.2</aws.kinesis.producer.version>
		<!-- org.apache.httpcomponents/httpclient -->
		<commons.httpclient.version>4.3.2</commons.httpclient.version>
		<!-- commons-httpclient/commons-httpclient -->
		<httpclient.classic.version>3.1</httpclient.classic.version>
		<commons.math3.version>3.4.1</commons.math3.version>
		<!-- managed up from 3.2.1 for SPARK-11652 -->
		<commons.collections.version>3.2.2</commons.collections.version>
		<scala.version>2.10.5</scala.version>
		<scala.binary.version>2.10</scala.binary.version>
		<jline.version>${scala.version}</jline.version>
		<jline.groupid>org.scala-lang</jline.groupid>
		<codehaus.jackson.version>1.9.13</codehaus.jackson.version>
		<fasterxml.jackson.version>2.5.3</fasterxml.jackson.version>
		<snappy.version>1.1.2</snappy.version>
		<netlib.java.version>1.1.2</netlib.java.version>
		<calcite.version>1.2.0-incubating</calcite.version>
		<commons-codec.version>1.10</commons-codec.version>
		<!-- org.apache.commons/commons-lang/ -->
		<commons-lang2.version>2.6</commons-lang2.version>
		<!-- org.apache.commons/commons-lang3/ -->
		<commons-lang3.version>3.3.2</commons-lang3.version>
		<datanucleus-core.version>3.2.10</datanucleus-core.version>
		<janino.version>2.7.8</janino.version>
		<jersey.version>1.9</jersey.version>
		<joda.version>2.9</joda.version>
		<jodd.version>3.5.2</jodd.version>
		<jsr305.version>1.3.9</jsr305.version>
		<libthrift.version>0.9.2</libthrift.version>
		<antlr.version>3.5.2</antlr.version>

		<test.java.home>${java.home}</test.java.home>
		<test.exclude.tags></test.exclude.tags>

		<!-- Dependency scopes that can be overridden by enabling certain profiles. These profiles are declared in the projects that build assemblies. For other projects the scope should 
			remain as "compile", otherwise they are not available during compilation if the dependency is transivite (e.g. "graphx/" depending on "core/" and needing Hadoop classes in the classpath 
			to compile). -->
		<flume.deps.scope>compile</flume.deps.scope>
		<hadoop.deps.scope>compile</hadoop.deps.scope>
		<hbase.deps.scope>compile</hbase.deps.scope>
		<hive.deps.scope>compile</hive.deps.scope>
		<parquet.deps.scope>compile</parquet.deps.scope>
		<parquet.test.deps.scope>test</parquet.test.deps.scope>

		<PermGen>64m</PermGen>
		<MaxPermGen>512m</MaxPermGen>
		<CodeCacheSize>512m</CodeCacheSize>
	</properties>

	<dependencies>
		<dependency>
			<groupId>com.huaban</groupId>
			<artifactId>jieba-analysis</artifactId>
			<version>1.0.2</version>
		</dependency>

		<dependency>
			<groupId>org.mongodb</groupId>
			<artifactId>mongo-java-driver</artifactId>
			<version>3.2.2</version>
		</dependency>

		<dependency>
			<groupId>org.mongodb</groupId>
			<artifactId>casbah-core_2.10</artifactId>
			<version>3.1.1</version>
		</dependency>

		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-core_${scala.binary.version}</artifactId>
			<version>${spark.version}</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-streaming_${scala.binary.version}</artifactId>
			<version>${spark.version}</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-mllib_${scala.binary.version}</artifactId>
			<version>${spark.version}</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-hive_${scala.binary.version}</artifactId>
			<version>${spark.version}</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-graphx_${scala.binary.version}</artifactId>
			<version>${spark.version}</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-streaming-twitter_${scala.binary.version}</artifactId>
			<version>${spark.version}</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-streaming-flume_${scala.binary.version}</artifactId>
			<version>${spark.version}</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-streaming-mqtt_${scala.binary.version}</artifactId>
			<version>${spark.version}</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-streaming-zeromq_${scala.binary.version}</artifactId>
			<version>${spark.version}</version>
			<exclusions>
				<exclusion>
					<groupId>org.spark-project.protobuf</groupId>
					<artifactId>protobuf-java</artifactId>
				</exclusion>
			</exclusions>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.spark</groupId>
			<artifactId>spark-streaming-kafka_${scala.binary.version}</artifactId>
			<version>${spark.version}</version>
		</dependency>
		<dependency>
			<groupId>org.apache.hbase</groupId>
			<artifactId>hbase-testing-util</artifactId>
			<version>${hbase.version}</version>
			<scope>${hbase.deps.scope}</scope>
			<exclusions>
				<exclusion>
					<!-- SPARK-4455 -->
					<groupId>org.apache.hbase</groupId>
					<artifactId>hbase-annotations</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.jruby</groupId>
					<artifactId>jruby-complete</artifactId>
				</exclusion>
			</exclusions>
		</dependency>
		<dependency>
			<groupId>org.apache.hbase</groupId>
			<artifactId>hbase-protocol</artifactId>
			<version>${hbase.version}</version>
			<scope>${hbase.deps.scope}</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.hbase</groupId>
			<artifactId>hbase-common</artifactId>
			<version>${hbase.version}</version>
			<scope>${hbase.deps.scope}</scope>
			<exclusions>
				<exclusion>
					<!-- SPARK-4455 -->
					<groupId>org.apache.hbase</groupId>
					<artifactId>hbase-annotations</artifactId>
				</exclusion>
			</exclusions>
		</dependency>
		<dependency>
			<groupId>org.apache.hbase</groupId>
			<artifactId>hbase-client</artifactId>
			<version>${hbase.version}</version>
			<scope>${hbase.deps.scope}</scope>
			<exclusions>
				<exclusion>
					<!-- SPARK-4455 -->
					<groupId>org.apache.hbase</groupId>
					<artifactId>hbase-annotations</artifactId>
				</exclusion>
				<exclusion>
					<groupId>io.netty</groupId>
					<artifactId>netty</artifactId>
				</exclusion>
			</exclusions>
		</dependency>
		<dependency>
			<groupId>org.apache.hbase</groupId>
			<artifactId>hbase-server</artifactId>
			<version>${hbase.version}</version>
			<scope>${hbase.deps.scope}</scope>
			<exclusions>
				<exclusion>
					<!-- SPARK-4455 -->
					<groupId>org.apache.hbase</groupId>
					<artifactId>hbase-annotations</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.hadoop</groupId>
					<artifactId>hadoop-core</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.hadoop</groupId>
					<artifactId>hadoop-client</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.hadoop</groupId>
					<artifactId>hadoop-mapreduce-client-jobclient</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.hadoop</groupId>
					<artifactId>hadoop-mapreduce-client-core</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.hadoop</groupId>
					<artifactId>hadoop-auth</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.hadoop</groupId>
					<artifactId>hadoop-annotations</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.hadoop</groupId>
					<artifactId>hadoop-hdfs</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.hbase</groupId>
					<artifactId>hbase-hadoop1-compat</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.commons</groupId>
					<artifactId>commons-math</artifactId>
				</exclusion>
				<exclusion>
					<groupId>com.sun.jersey</groupId>
					<artifactId>jersey-core</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.slf4j</groupId>
					<artifactId>slf4j-api</artifactId>
				</exclusion>
				<exclusion>
					<groupId>com.sun.jersey</groupId>
					<artifactId>jersey-server</artifactId>
				</exclusion>
				<exclusion>
					<groupId>com.sun.jersey</groupId>
					<artifactId>jersey-core</artifactId>
				</exclusion>
				<exclusion>
					<groupId>com.sun.jersey</groupId>
					<artifactId>jersey-json</artifactId>
				</exclusion>
				<exclusion>
					<!-- hbase uses v2.4, which is better, but ... -->
					<groupId>commons-io</groupId>
					<artifactId>commons-io</artifactId>
				</exclusion>
			</exclusions>
		</dependency>
		<dependency>
			<groupId>org.apache.hbase</groupId>
			<artifactId>hbase-hadoop-compat</artifactId>
			<version>${hbase.version}</version>
			<scope>${hbase.deps.scope}</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.hbase</groupId>
			<artifactId>hbase-hadoop-compat</artifactId>
			<version>${hbase.version}</version>
			<type>test-jar</type>
			<scope>test</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.commons</groupId>
			<artifactId>commons-math3</artifactId>
			<version>${commons.math3.version}</version>
			<scope>provided</scope>
		</dependency>
		<dependency>
			<groupId>com.twitter</groupId>
			<artifactId>algebird-core_${scala.binary.version}</artifactId>
			<version>0.9.0</version>
		</dependency>
		<dependency>
			<groupId>org.scalacheck</groupId>
			<artifactId>scalacheck_${scala.binary.version}</artifactId>
			<version>1.11.3</version>
			<scope>test</scope>
		</dependency>
		<dependency>
			<groupId>org.apache.cassandra</groupId>
			<artifactId>cassandra-all</artifactId>
			<version>1.2.6</version>
			<exclusions>
				<exclusion>
					<groupId>com.google.guava</groupId>
					<artifactId>guava</artifactId>
				</exclusion>
				<exclusion>
					<groupId>com.googlecode.concurrentlinkedhashmap</groupId>
					<artifactId>concurrentlinkedhashmap-lru</artifactId>
				</exclusion>
				<exclusion>
					<groupId>com.ning</groupId>
					<artifactId>compress-lzf</artifactId>
				</exclusion>
				<exclusion>
					<groupId>commons-cli</groupId>
					<artifactId>commons-cli</artifactId>
				</exclusion>
				<exclusion>
					<groupId>commons-codec</groupId>
					<artifactId>commons-codec</artifactId>
				</exclusion>
				<exclusion>
					<groupId>commons-lang</groupId>
					<artifactId>commons-lang</artifactId>
				</exclusion>
				<exclusion>
					<groupId>commons-logging</groupId>
					<artifactId>commons-logging</artifactId>
				</exclusion>
				<exclusion>
					<groupId>io.netty</groupId>
					<artifactId>netty</artifactId>
				</exclusion>
				<exclusion>
					<groupId>jline</groupId>
					<artifactId>jline</artifactId>
				</exclusion>
				<exclusion>
					<groupId>net.jpountz.lz4</groupId>
					<artifactId>lz4</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.cassandra.deps</groupId>
					<artifactId>avro</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.commons</groupId>
					<artifactId>commons-math3</artifactId>
				</exclusion>
				<exclusion>
					<groupId>org.apache.thrift</groupId>
					<artifactId>libthrift</artifactId>
				</exclusion>
			</exclusions>
		</dependency>
		<dependency>
			<groupId>com.github.scopt</groupId>
			<artifactId>scopt_${scala.binary.version}</artifactId>
			<version>3.2.0</version>
		</dependency>

		<dependency>
			<groupId>org.json4s</groupId>
			<artifactId>json4s-native_${scala.binary.version}</artifactId>
			<version>3.2.10</version>
		</dependency>

		<dependency>
			<groupId>org.json4s</groupId>
			<artifactId>json4s-jackson_${scala.binary.version}</artifactId>
			<version>3.2.10</version>
		</dependency>

		<dependency>
			<groupId>au.com.bytecode</groupId>
			<artifactId>opencsv</artifactId>
			<version>2.4</version>
		</dependency>

		<dependency>
			<groupId>mysql</groupId>
			<artifactId>mysql-connector-java</artifactId>
			<version>5.1.38</version>
		</dependency>

		<dependency>
			<groupId>com.github.etaty</groupId>
			<artifactId>rediscala_2.10</artifactId>
			<version>1.6.0</version>
		</dependency>

		<dependency>
			<groupId>com.alibaba</groupId>
			<artifactId>fastjson</artifactId>
			<version>1.2.7</version>
		</dependency>

		<dependency>
			<groupId>redis.clients</groupId>
			<artifactId>jedis</artifactId>
			<version>2.8.1</version>
		</dependency>

		<dependency>
			<groupId>com.github.fommil.netlib</groupId>
			<artifactId>all</artifactId>
			<version>1.1.2</version>
			<type>pom</type>
		</dependency>

		<!-- The following dependencies are already present in the Spark assembly, so we want to force them to be provided. -->
		<dependency>
			<groupId>org.scala-lang</groupId>
			<artifactId>scala-library</artifactId>
			<version>${scala.version}</version>
			<scope>provided</scope>
		</dependency>

	</dependencies>

	<build>
		<outputDirectory>target/scala-${scala.binary.version}/classes</outputDirectory>
		<testOutputDirectory>target/scala-${scala.binary.version}/test-classes</testOutputDirectory>
		<plugins>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-compiler-plugin</artifactId>
				<configuration>
					<source>1.7</source>
					<target>1.7</target>
					<encoding>UTF-8</encoding>
				</configuration>
			</plugin>
			<plugin>
				<groupId>net.alchim31.maven</groupId>
				<artifactId>scala-maven-plugin</artifactId>
				<version>3.2.2</version>
				<executions>
					<execution>
						<id>eclipse-add-source</id>
						<goals>
							<goal>add-source</goal>
						</goals>
					</execution>
					<execution>
						<id>scala-compile-first</id>
						<phase>process-resources</phase>
						<goals>
							<goal>compile</goal>
						</goals>
					</execution>
					<execution>
						<id>scala-test-compile-first</id>
						<phase>process-test-resources</phase>
						<goals>
							<goal>testCompile</goal>
						</goals>
					</execution>
					<execution>
						<id>attach-scaladocs</id>
						<phase>verify</phase>
						<goals>
							<goal>doc-jar</goal>
						</goals>
					</execution>
				</executions>
				<configuration>
					<scalaVersion>${scala.version}</scalaVersion>
					<recompileMode>incremental</recompileMode>
					<useZincServer>true</useZincServer>
					<args>
						<arg>-unchecked</arg>
						<arg>-deprecation</arg>
						<arg>-feature</arg>
					</args>
					<jvmArgs>
						<jvmArg>-Xms1024m</jvmArg>
						<jvmArg>-Xmx1024m</jvmArg>
						<jvmArg>-XX:PermSize=${PermGen}</jvmArg>
						<jvmArg>-XX:MaxPermSize=${MaxPermGen}</jvmArg>
						<jvmArg>-XX:ReservedCodeCacheSize=${CodeCacheSize}</jvmArg>
					</jvmArgs>
					<javacArgs>
						<javacArg>-source</javacArg>
						<javacArg>${java.version}</javacArg>
						<javacArg>-target</javacArg>
						<javacArg>${java.version}</javacArg>
						<javacArg>-Xlint:all,-serial,-path</javacArg>
					</javacArgs>
				</configuration>
			</plugin>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-deploy-plugin</artifactId>
				<configuration>
					<skip>true</skip>
				</configuration>
			</plugin>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-install-plugin</artifactId>
				<configuration>
					<skip>true</skip>
				</configuration>
			</plugin>
			<plugin>
				<groupId>org.apache.maven.plugins</groupId>
				<artifactId>maven-shade-plugin</artifactId>
				<executions>
					<execution>
						<phase>package</phase>
						<goals>
							<goal>shade</goal>
						</goals>
					</execution>
				</executions>
				<configuration>
					<shadedArtifactAttached>false</shadedArtifactAttached>
					<outputFile>${project.build.directory}/spark-examples-${project.version}-hadoop${hadoop.version}.jar</outputFile>
					<artifactSet>
						<includes>
							<include>*:*</include>
						</includes>
					</artifactSet>
					<filters>
						<filter>
							<artifact>*:*</artifact>
							<excludes>
								<exclude>META-INF/*.SF</exclude>
								<exclude>META-INF/*.DSA</exclude>
								<exclude>META-INF/*.RSA</exclude>
							</excludes>
						</filter>
					</filters>
					<transformers>
						<transformer implementation="org.apache.maven.plugins.shade.resource.ServicesResourceTransformer" />
						<transformer implementation="org.apache.maven.plugins.shade.resource.AppendingTransformer">
							<resource>reference.conf</resource>
						</transformer>
						<transformer implementation="org.apache.maven.plugins.shade.resource.DontIncludeResourceTransformer">
							<resource>log4j.properties</resource>
						</transformer>
					</transformers>
				</configuration>
			</plugin>
		</plugins>
	</build>
	<profiles>
		<profile>
			<id>kinesis-asl</id>
			<dependencies>
				<dependency>
					<groupId>org.apache.spark</groupId>
					<artifactId>spark-streaming-kinesis-asl_${scala.binary.version}</artifactId>
					<version>${project.version}</version>
				</dependency>
			</dependencies>
		</profile>

		<!-- Profiles that disable inclusion of certain dependencies. -->
		<profile>
			<id>flume-provided</id>
			<properties>
				<flume.deps.scope>provided</flume.deps.scope>
			</properties>
		</profile>
		<profile>
			<id>hadoop-provided</id>
			<properties>
				<hadoop.deps.scope>provided</hadoop.deps.scope>
			</properties>
		</profile>
		<profile>
			<id>hbase-provided</id>
			<properties>
				<hbase.deps.scope>provided</hbase.deps.scope>
			</properties>
		</profile>
		<profile>
			<id>hive-provided</id>
			<properties>
				<hive.deps.scope>provided</hive.deps.scope>
			</properties>
		</profile>
		<profile>
			<id>parquet-provided</id>
			<properties>
				<parquet.deps.scope>provided</parquet.deps.scope>
			</properties>
		</profile>
	</profiles>

</project>